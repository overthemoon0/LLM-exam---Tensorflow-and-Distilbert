{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM Science exam\n\nMost of the notebooks in this competition are based on implemenatation via Pytorch and Deberta.\nThis notebook suggests slightly different approach via Tensorflow and Distilbert.","metadata":{}},{"cell_type":"markdown","source":"## Importing dependencies","metadata":{}},{"cell_type":"code","source":"#Import  dependencies\n\nimport tensorflow as tf\nfrom typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import TFBertForMultipleChoice, EarlyStoppingCallback, BertTokenizer, DistilBertTokenizer, TFDistilBertForMultipleChoice\nfrom transformers.optimization import Adafactor\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras import callbacks\npd.set_option('display.max_colwidth', 1000)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:22:34.570910Z","iopub.execute_input":"2023-09-08T13:22:34.571183Z","iopub.status.idle":"2023-09-08T13:22:58.660159Z","shell.execute_reply.started":"2023-09-08T13:22:34.571157Z","shell.execute_reply":"2023-09-08T13:22:58.659224Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"Apart from the training dataset from the competition that consists of only 200 rows, we will use the additional datasets with further examples, generated by \nRADEK OSMULSKI (https://www.kaggle.com/datasets/radek1/additional-train-data-for-llm-science-exam)","metadata":{}},{"cell_type":"code","source":"df_train = pd.concat([\n    pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv'),\n    pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv'),\n    pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv'),\n    pd.read_csv('/kaggle/input/15k-high-quality-examples/15k_gpt3.5-turbo.csv')\n])\ndf_train.drop('id', inplace = True, axis = 1)\ndf_test = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:22:58.662860Z","iopub.execute_input":"2023-09-08T13:22:58.663134Z","iopub.status.idle":"2023-09-08T13:22:59.017016Z","shell.execute_reply.started":"2023-09-08T13:22:58.663110Z","shell.execute_reply":"2023-09-08T13:22:59.015987Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#distilbert-base-uncased\ntokenizer = DistilBertTokenizer.from_pretrained(\"/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\")\nmodel = TFDistilBertForMultipleChoice.from_pretrained(\"/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:22:59.018343Z","iopub.execute_input":"2023-09-08T13:22:59.018953Z","iopub.status.idle":"2023-09-08T13:23:17.919398Z","shell.execute_reply.started":"2023-09-08T13:22:59.018919Z","shell.execute_reply":"2023-09-08T13:23:17.918407Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at /kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased were not used when initializing TFDistilBertForMultipleChoice: ['activation_13', 'vocab_projector', 'vocab_transform', 'vocab_layer_norm']\n- This IS expected if you are initializing TFDistilBertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained(\"/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\")\n# credit to https://www.kaggle.com/code/satyaprakashshukl/kaggle-llm-science/notebook\nimport random\nimport pandas as pd\nfrom transformers import pipeline, AutoTokenizer\n\n\n# Initialize the pipeline for masked language modeling using BERT\nmlm_fill_mask = pipeline(task=\"fill-mask\", model=\"/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\")\n\n# Function to perform data augmentation using different techniques\ndef augment_data(original_df, num_augmented_rows):\n    augmented_data = []\n    original_rows = original_df.shape[0]\n\n    # Function for contextual word embeddings augmentation\n    def contextual_embeddings(text):\n        # Tokenize the text\n        tokenized_text = tokenizer(text, return_tensors=\"tf\")\n\n        # Find masked positions in the tokenized text\n        masked_positions = [i for i, token in enumerate(tokenized_text[\"input_ids\"][0]) if token == tokenizer.mask_token_id]\n\n        # If no masked positions found, return the original text\n        if not masked_positions:\n            return text\n\n        # Randomly select one of the masked positions\n        random_masked_position = random.choice(masked_positions)\n\n        # Predict the masked word using masked language modeling\n        masked_text = text.replace(\"[MASK]\", tokenizer.mask_token)\n        predicted_word = mlm_fill_mask(masked_text)[0][\"token_str\"]\n\n        # Replace the masked word in the text with the predicted word\n        augmented_text = text.replace(tokenizer.mask_token, predicted_word, 1)\n\n        return augmented_text\n\n    # Function for synonym replacement augmentation\n    def augment_with_synonyms(text):\n        # You can use your own synonym replacement logic here\n        # For simplicity, let's assume we have a predefined dictionary of synonyms\n        synonym_dict = {\n            \"good\": [\"excellent\", \"great\", \"superb\", \"fine\"],\n            \"bad\": [\"poor\", \"terrible\", \"awful\", \"horrible\"]\n            # Add more synonyms as needed\n        }\n\n        words = text.split()\n        augmented_words = [synonym_dict[word][random.randint(0, len(synonym_dict[word]) - 1)] if word in synonym_dict else word for word in words]\n        return \" \".join(augmented_words)\n\n    for _ in range(num_augmented_rows):\n        original_row = original_df.iloc[random.randint(0, original_rows - 1)]\n        augmented_row = original_row.copy()\n\n        # Apply augmentation techniques to \"prompt\"\n        augmented_row[\"prompt\"] = contextual_embeddings(original_row[\"prompt\"])\n\n        # Apply synonym replacement to answer choices (A, B, C, D, E)\n        for choice in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n            augmented_row[choice] = augment_with_synonyms(original_row[choice])\n\n        augmented_data.append(augmented_row)\n\n    return augmented_data\n\n# Assuming you have a concatenated_df dataframe with columns: \"prompt\", \"A\", \"B\", \"C\", \"D\", \"E\", and \"answer\"\n# Set the desired number of rows\ndesired_rows = 30000\n\n# Calculate the number of rows needed to achieve the desired total rows\nadditional_rows = desired_rows - df_train.shape[0]\n\n# Augment the data\naugmented_data = augment_data(df_train, additional_rows)\n\n# Convert the augmented data to a dataframe\naugmented_df = pd.DataFrame(augmented_data)\n\n# Concatenate the original dataframe with the augmented dataframe to get the final dataframe with 3000 rows\ndf_train = pd.concat([df_train, augmented_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:23:17.922205Z","iopub.execute_input":"2023-09-08T13:23:17.922729Z","iopub.status.idle":"2023-09-08T13:25:46.268080Z","shell.execute_reply.started":"2023-09-08T13:23:17.922673Z","shell.execute_reply":"2023-09-08T13:25:46.267029Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train, df_val = train_test_split(\n    df_train, test_size=0.1, random_state=42, stratify = df_train['answer'] )\n\nprint(df_train.shape, df_val.shape, df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:46.269572Z","iopub.execute_input":"2023-09-08T13:25:46.270038Z","iopub.status.idle":"2023-09-08T13:25:46.332376Z","shell.execute_reply.started":"2023-09-08T13:25:46.270003Z","shell.execute_reply":"2023-09-08T13:25:46.331309Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(27000, 7) (3000, 7) (200, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test['answer'] = 'A'","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:46.333961Z","iopub.execute_input":"2023-09-08T13:25:46.334322Z","iopub.status.idle":"2023-09-08T13:25:46.340169Z","shell.execute_reply.started":"2023-09-08T13:25:46.334288Z","shell.execute_reply":"2023-09-08T13:25:46.339069Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:46.341966Z","iopub.execute_input":"2023-09-08T13:25:46.342528Z","iopub.status.idle":"2023-09-08T13:25:46.365629Z","shell.execute_reply.started":"2023-09-08T13:25:46.342495Z","shell.execute_reply":"2023-09-08T13:25:46.364703Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                                           prompt  \\\n19966       Which species of Calceolaria was described by the authors Ruiz & Pav?   \n8569   What was the purpose of \"possibility points\" in the roleplaying game Torg?   \n\n                                                                                         A  \\\n19966                                                                   Calceolaria glauca   \n8569   Possibility points determined character creation and limited the choices available.   \n\n                                                                               B  \\\n19966                                                        Calceolaria inflexa   \n8569   Possibility points had no specific purpose and were not used in the game.   \n\n                                                                            C  \\\n19966                                                    Calceolaria flexuosa   \n8569   Possibility points could only be spent to improve character abilities.   \n\n                                                                                                       D  \\\n19966                                                                                Calceolaria hispida   \n8569   Possibility points could be spent to achieve certain effects, such as healing or warping reality.   \n\n                                                                                     E  \\\n19966                                                        Calceolaria incachacensis   \n8569   Possibility points only existed as an in-game phenomenon with no practical use.   \n\n      answer  \n19966      A  \n8569       D  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19966</th>\n      <td>Which species of Calceolaria was described by the authors Ruiz &amp; Pav?</td>\n      <td>Calceolaria glauca</td>\n      <td>Calceolaria inflexa</td>\n      <td>Calceolaria flexuosa</td>\n      <td>Calceolaria hispida</td>\n      <td>Calceolaria incachacensis</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>8569</th>\n      <td>What was the purpose of \"possibility points\" in the roleplaying game Torg?</td>\n      <td>Possibility points determined character creation and limited the choices available.</td>\n      <td>Possibility points had no specific purpose and were not used in the game.</td>\n      <td>Possibility points could only be spent to improve character abilities.</td>\n      <td>Possibility points could be spent to achieve certain effects, such as healing or warping reality.</td>\n      <td>Possibility points only existed as an in-game phenomenon with no practical use.</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for col in df_train.columns[:-1]:\n    print(f'the longest string in {col} column: {df_train[col].str.len().max()}')\n    print(f'the average length of the string in {col} column: {df_train[col].str.len().mean()}') \n    # some strings are longer than 512. We will not truncate the strings during preprocessing","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:46.366917Z","iopub.execute_input":"2023-09-08T13:25:46.367220Z","iopub.status.idle":"2023-09-08T13:25:46.578127Z","shell.execute_reply.started":"2023-09-08T13:25:46.367192Z","shell.execute_reply":"2023-09-08T13:25:46.577170Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"the longest string in prompt column: 383\nthe average length of the string in prompt column: 83.73370370370371\nthe longest string in A column: 674\nthe average length of the string in A column: 73.53333333333333\nthe longest string in B column: 683\nthe average length of the string in B column: 73.43455555555556\nthe longest string in C column: 677\nthe average length of the string in C column: 73.43270370370371\nthe longest string in D column: 746\nthe average length of the string in D column: 73.52044444444445\nthe longest string in E column: 695\nthe average length of the string in E column: 73.39011111111111\n","output_type":"stream"}]},{"cell_type":"code","source":"sns.countplot(df_train, x = 'answer') # validating that the classes are uniformly distributed","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:46.579736Z","iopub.execute_input":"2023-09-08T13:25:46.580084Z","iopub.status.idle":"2023-09-08T13:25:46.908888Z","shell.execute_reply.started":"2023-09-08T13:25:46.580051Z","shell.execute_reply":"2023-09-08T13:25:46.907960Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='answer', ylabel='count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"df_train = Dataset.from_pandas(df_train)\ndf_val = Dataset.from_pandas(df_val)\ndf_test = Dataset.from_pandas(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:46.912938Z","iopub.execute_input":"2023-09-08T13:25:46.913825Z","iopub.status.idle":"2023-09-08T13:25:46.990704Z","shell.execute_reply.started":"2023-09-08T13:25:46.913789Z","shell.execute_reply":"2023-09-08T13:25:46.989774Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Adapted from Huggingface Multiple Choice https://huggingface.co/docs/transformers/tasks/multiple_choice\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True) # tokenizer call using 'text_pair' which basically just adds a separator between the two sentences\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:46.992016Z","iopub.execute_input":"2023-09-08T13:25:46.992363Z","iopub.status.idle":"2023-09-08T13:25:46.999675Z","shell.execute_reply.started":"2023-09-08T13:25:46.992332Z","shell.execute_reply":"2023-09-08T13:25:46.998781Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, TFRobertaForMultipleChoice\n\n#distilroberta-base\n#tokenizer = RobertaTokenizer.from_pretrained('/kaggle/input/huggingface-roberta-variants/archive/distilroberta-base/distilroberta-base')\n#model = TFRobertaForMultipleChoice.from_pretrained('/kaggle/input/huggingface-roberta-variants/archive/distilroberta-base/distilroberta-base')","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:47.001078Z","iopub.execute_input":"2023-09-08T13:25:47.001665Z","iopub.status.idle":"2023-09-08T13:25:47.021190Z","shell.execute_reply.started":"2023-09-08T13:25:47.001630Z","shell.execute_reply":"2023-09-08T13:25:47.020170Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#xlm-roberta-base\n#tokenizer = RobertaTokenizer.from_pretrained('/kaggle/input/huggingface-roberta-variants/archive/roberta-large-mnli/roberta-large-mnli')\n#model = TFRobertaForMultipleChoice.from_pretrained('/kaggle/input/huggingface-roberta-variants/archive/tf-xlm-roberta-base/tf-xlm-roberta-base')","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:47.022318Z","iopub.execute_input":"2023-09-08T13:25:47.023278Z","iopub.status.idle":"2023-09-08T13:25:47.027230Z","shell.execute_reply.started":"2023-09-08T13:25:47.023246Z","shell.execute_reply":"2023-09-08T13:25:47.026287Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenized_train_ds = df_train.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_val_ds = df_val.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_test_ds = df_test.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:25:47.028467Z","iopub.execute_input":"2023-09-08T13:25:47.029334Z","iopub.status.idle":"2023-09-08T13:29:01.285882Z","shell.execute_reply.started":"2023-09-08T13:25:47.029303Z","shell.execute_reply":"2023-09-08T13:29:01.284923Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/27000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44c08408eb13428b876690b7b0849cb9"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d505afd2d8f477691be0108ec825442"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"562a1b68ee0145b08f08a0d93b263037"}},"metadata":{}}]},{"cell_type":"code","source":"\n@dataclass\nclass DataCollatorForMultipleChoice:\n    \"\"\"\n    Data collator that will dynamically pad the inputs for multiple choice received.\n    \"\"\"\n\n    tokenizer:  tokenizer #PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n\n    def __call__(self, features):\n        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0][\"input_ids\"])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n\n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"tf\",\n        )\n\n        batch = {k: tf.reshape(v, (batch_size, num_choices, -1)) for k, v in batch.items()}\n        batch[\"labels\"] = tf.convert_to_tensor(labels, dtype=tf.int16)\n        return batch\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:01.287569Z","iopub.execute_input":"2023-09-08T13:29:01.287960Z","iopub.status.idle":"2023-09-08T13:29:01.299413Z","shell.execute_reply.started":"2023-09-08T13:29:01.287924Z","shell.execute_reply":"2023-09-08T13:29:01.298332Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"batch_size = 8\n#steps_per_epoch = 200\nnum_train_epochs = 10\nlearning_rate = 1e-4\n\noptimizer = tf.keras.optimizers.Adafactor(\n    learning_rate=1e-4,  \n    weight_decay=0.01)             \n    \nmodel.compile(\n    optimizer=optimizer,\n    metrics=[\n        'accuracy'\n    ],\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:01.300975Z","iopub.execute_input":"2023-09-08T13:29:01.301638Z","iopub.status.idle":"2023-09-08T13:29:01.331791Z","shell.execute_reply.started":"2023-09-08T13:29:01.301605Z","shell.execute_reply":"2023-09-08T13:29:01.330948Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"EarlyStopping = tf.keras.callbacks.EarlyStopping(\n                    monitor=\"val_loss\",\n                    patience=20,\n                    restore_best_weights=True,\n                    start_from_epoch=5,\n                )\nreduce_lr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n                                              factor=0.8, \n                                              patience=2,\n                                              verbose=1, \n                                              min_lr=1e-7)\ncheckpoint_path = \"fine_tune_checkpoints/\"\nmodel_checkpoint = callbacks.ModelCheckpoint(checkpoint_path,\n                                                      save_weights_only=True,\n                                                      save_best_only=True,\n                                                      monitor=\"val_loss\")","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:01.333163Z","iopub.execute_input":"2023-09-08T13:29:01.333512Z","iopub.status.idle":"2023-09-08T13:29:01.339768Z","shell.execute_reply.started":"2023-09-08T13:29:01.333481Z","shell.execute_reply":"2023-09-08T13:29:01.338610Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tf_train_set = model.prepare_tf_dataset(\n    tokenized_train_ds,\n    shuffle=False,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n)\n\ntf_validation_set = model.prepare_tf_dataset(\n    tokenized_val_ds,\n    shuffle=False,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n)\n\ntf_test_set = model.prepare_tf_dataset(\n    tokenized_test_ds,\n    shuffle=False,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:01.341398Z","iopub.execute_input":"2023-09-08T13:29:01.341821Z","iopub.status.idle":"2023-09-08T13:29:01.779386Z","shell.execute_reply.started":"2023-09-08T13:29:01.341784Z","shell.execute_reply":"2023-09-08T13:29:01.778409Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nkfold = KFold(n_splits = 3)\nmodels = {}\n\nfor fold, (train_ids, test_ids) in enumerate(kfold.split(tokenized_train_ds)):\n    print(f'FOLD {fold}')\n    print('--------------------------------')\n    \n    # Subset the dataset.\n    train_subset = tokenized_train_ds.select(train_ids)\n    test_subset = tokenized_train_ds.select(test_ids)\n    \n    train_subset = model.prepare_tf_dataset(\n    train_subset,\n    shuffle=False,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n    )\n\n    test_subset = model.prepare_tf_dataset(\n    test_subset,\n    shuffle=False,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n    )\n    \n    # Create a new instance of the model for each fold.\n    #model = TFDistilBertForMultipleChoice.from_pretrained(str(fold) + \"DistillBert\")\n\n    model.compile(\n    optimizer=optimizer,\n    metrics=[\n        'accuracy'\n    ],\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n\n    model.fit(\n    tf_train_set,\n    validation_data=tf_validation_set,\n    epochs = num_train_epochs,\n    #batch_size = batch_size,\n    callbacks=[EarlyStopping, reduce_lr, model_checkpoint],\n    steps_per_epoch = 200\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:47:38.317497Z","iopub.execute_input":"2023-09-08T13:47:38.317892Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"FOLD 0\n--------------------------------\nEpoch 1/10\n200/200 [==============================] - 196s 768ms/step - loss: 1.6084 - accuracy: 0.2069 - val_loss: 1.6061 - val_accuracy: 0.2997 - lr: 1.0000e-04\nEpoch 2/10\n200/200 [==============================] - 110s 549ms/step - loss: 1.6049 - accuracy: 0.2181 - val_loss: 1.5951 - val_accuracy: 0.3420 - lr: 1.0000e-04\nEpoch 3/10\n200/200 [==============================] - 107s 534ms/step - loss: 1.5763 - accuracy: 0.3081 - val_loss: 1.5486 - val_accuracy: 0.3620 - lr: 1.0000e-04\nEpoch 4/10\n200/200 [==============================] - ETA: 0s - loss: 1.5441 - accuracy: 0.3237","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(\n    tf_train_set,\n    validation_data=tf_validation_set,\n    epochs = num_train_epochs,\n    #batch_size = batch_size,\n    callbacks=[EarlyStopping, reduce_lr, model_checkpoint],\n    steps_per_epoch = 200\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:03.771419Z","iopub.status.idle":"2023-09-08T13:29:03.773975Z","shell.execute_reply.started":"2023-09-08T13:29:03.773727Z","shell.execute_reply":"2023-09-08T13:29:03.773751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation loss\nplt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Plot the training and validation accuracy\nplt.plot(history.history['accuracy'], label='train_accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:03.776981Z","iopub.status.idle":"2023-09-08T13:29:03.780048Z","shell.execute_reply.started":"2023-09-08T13:29:03.779804Z","shell.execute_reply":"2023-09-08T13:29:03.779828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:03.781419Z","iopub.status.idle":"2023-09-08T13:29:03.783916Z","shell.execute_reply.started":"2023-09-08T13:29:03.783621Z","shell.execute_reply":"2023-09-08T13:29:03.783648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting on the test set ","metadata":{}},{"cell_type":"code","source":"df_test = pd.DataFrame(df_test) # back to Pandas\ntest_predictions = model.predict(tf_test_set).logits\npredictions_as_ids = np.argsort(-test_predictions, 1)\npredictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\npredictions_as_string = df_test['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]\nprint(predictions_as_string[:3])","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:03.792186Z","iopub.status.idle":"2023-09-08T13:29:03.792955Z","shell.execute_reply.started":"2023-09-08T13:29:03.792703Z","shell.execute_reply":"2023-09-08T13:29:03.792740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = df_test[['id', 'prediction']]\nsubmission.to_csv('submission.csv', index=False)\n\npd.read_csv('submission.csv').head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T13:29:03.794246Z","iopub.status.idle":"2023-09-08T13:29:03.794998Z","shell.execute_reply.started":"2023-09-08T13:29:03.794766Z","shell.execute_reply":"2023-09-08T13:29:03.794789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## More to do","metadata":{}},{"cell_type":"markdown","source":"- Implement cross-validation\n- Augmentation using Google translate from and to EN.\n\n","metadata":{}}]}